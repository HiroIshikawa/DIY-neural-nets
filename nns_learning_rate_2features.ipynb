{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training With Alpha:0.0001\n",
      "Error:0.499754731319\n",
      "Error:0.495820572435\n",
      "Error:0.49199917054\n",
      "Error:0.4882000124\n",
      "Error:0.48434135284\n",
      "Error:0.480348227251\n",
      "Error:0.476150878647\n",
      "Error:0.471683627966\n",
      "Error:0.46688418429\n",
      "Error:0.461693389992\n",
      "\n",
      "Output After Training:\n",
      "[[ 0.50717481]\n",
      " [ 0.50717481]\n",
      " [ 0.59506281]\n",
      " [ 0.59506281]]\n",
      "\n",
      "Training With Alpha:10\n",
      "Error:0.499754731319\n",
      "Error:0.00152288249106\n",
      "Error:0.00106062132494\n",
      "Error:0.000858124864207\n",
      "Error:0.000738270927933\n",
      "Error:0.000656913661611\n",
      "Error:0.000597115675117\n",
      "Error:0.000550808346178\n",
      "Error:0.000513597632367\n",
      "Error:0.00048286045523\n",
      "\n",
      "Output After Training:\n",
      "[[  4.58467401e-04]\n",
      " [  4.58467401e-04]\n",
      " [  9.99544619e-01]\n",
      " [  9.99544619e-01]]\n",
      "\n",
      "Training With Alpha:100000\n",
      "Error:0.499754731319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiro99ishikawa/anaconda/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:5: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "Error:0.0\n",
      "\n",
      "Output After Training:\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sigmoid for binary problem\n",
    "def nonlin(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# derivative of sigmoid\n",
    "def drv_nonlin(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "# input dataset\n",
    "X = np.array([ [0,1],\n",
    "               [0,1],\n",
    "               [1,0],\n",
    "               [1,0] ])\n",
    "\n",
    "# output dataset\n",
    "# y = np.array([ [0],\n",
    "#                [0],\n",
    "#                [1],\n",
    "#                [1] ])\n",
    "# or simplify\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "alphas = [0.0001, 10, 100000]\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"\\nTraining With Alpha:\" + str(alpha))\n",
    "\n",
    "    # seed random numbers to make calculation\n",
    "    # this is neccessary to observe the result under same random numbers in one session\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # hidden layer configuration.\n",
    "    # 3 layear: You need to configure synapse 0 and synapse 1 here.\n",
    "    synapse_0 = 2* np.random.random((2, 4)) - 1 # 2x4\n",
    "    synapse_1 = 2* np.random.random((4, 1)) - 1 # 4x1\n",
    "\n",
    "    # start training iterations (10k times)\n",
    "    for i in range(100000):\n",
    "        # iteration start\n",
    "        num_iter = i\n",
    "\n",
    "        # ---- training iteration step 1: Forward Propagation\n",
    "        # Forward Propagation applies weights of synapses in each layer to produce output layer\n",
    "        # Output layer is the layer that is the last layer as a final output for an iteration of training\n",
    "        # the initial layer is the input\n",
    "        l0 = X # 4x2\n",
    "        # the hidden layer after application of the first synapse weights to layer 0 values, which is the input\n",
    "        l0_weighted = np.dot(l0,synapse_0) # 4x2 2x4 -> 4x4\n",
    "        # smooth each weighted value into new value ranging [0, 1)\n",
    "        # now we generated the hidden layer, l1\n",
    "        l1 = nonlin(l0_weighted) # -> 4x4\n",
    "\n",
    "        # we finally compute the output layer by applying the second synapse weights to layer 1 values\n",
    "        l1_weighted = np.dot(l1,synapse_1) # 4x4 4x1 -> 4x1\n",
    "        # smooth each weighted value into new value ranging [0, 1)\n",
    "        # now we generated the hidden layer, l1\n",
    "        l2 = nonlin(l1_weighted) # -> 4x1\n",
    "        # ---- Forward Propagation completed\n",
    "\n",
    "\n",
    "        # ---- training iteration step 2: Back Propagation\n",
    "        # Back Propagation adjust each weight of synapse layer by layer\n",
    "\n",
    "        # First we figure out the initial error amount and direction on the output layer relative to the given output y\n",
    "        l2_error = y - l2 # 4x1 - 4x1 -> 4x1\n",
    "        # Incorporate the derivative of sigmoid on layer 2 (output layer)\n",
    "        l2_delta = l2_error * drv_nonlin(l2) # 4x1 4x1 -> 4x1\n",
    "        # Apply the delta computed to each synapses for the next iteration of training\n",
    "        synapse_1 += alpha*l1.T.dot(l2_delta) # 4x4.T(=4x4) 4x1 -> 4x1\n",
    "\n",
    "        # How much weights of synapse 1 contributed to the l2_delta\n",
    "        l1_error = l2_delta.dot(synapse_1.T) # 4x1 4x1.T(=1x4) -> 4x4 \n",
    "        # Incorporate the derivative of sigmoid on layer 1 (hidden layer)\n",
    "        l1_delta = l1_error * drv_nonlin(l1) # 4x4 4x4 -> 4x4    \n",
    "        # Apply the delta computed to each synapses for the next iteration of training\n",
    "        synapse_0 += alpha*l0.T.dot(l1_delta) # 4x2.T(=2x4) 4x4 -> 2x4 \n",
    "        # ---- Back Propagation completed\n",
    "\n",
    "        # Checking error of the output layer respects to given output for each 10000 iterations\n",
    "        # The number should decrease over the iterations\n",
    "        if (num_iter% 10000) == 0:\n",
    "            print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
    "\n",
    "\n",
    "    print('')\n",
    "    print(\"Output After Training:\")\n",
    "    print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
